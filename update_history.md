## 2022-1-24
- Gan, Zhe and Chen, Yen-Chun and Li, Linjie and Chen, Tianlong and Cheng, Yu and Wang, Shuohang and Liu, Jingjing and Wang, Lijuan and Liu, Zicheng,**Playing Lottery Tickets with Vision and Language**,arXiv:2104.11832 [cs] 2021 [[Paper]](http://arxiv.org/abs/2104.11832)
 
- Gao, Chenyu and Zhu, Qi and Wang, Peng and Wu, Qi,**Chop Chop BERT: Visual Question Answering by Chopping VisualBERT's Heads**,arXiv:2104.14741 [cs] 2021 [[Paper]](http://arxiv.org/abs/2104.14741)

- Gong, Haifan and Chen, Guanqi and Liu, Sishuo and Yu, Yizhou and Li, Guanbin,**Cross-Modal Self-Attention with Multi-Task Pre-Training for Medical Visual Question Answering**,arXiv:2105.00136 [cs] 2021 [[Paper]](http://arxiv.org/abs/2105.00136)

- Do, Tuong and Nguyen, Binh X. and Tjiputra, Erman and Tran, Minh and Tran, Quang D. and Nguyen, Anh,**Multiple Meta-model Quantifying for Medical Visual Question Answering**,arXiv:2105.08913 [cs] 2021 [[Paper]](http://arxiv.org/abs/2105.08913)

- Dey, Arka Ujjal and Valveny, Ernest and Harit, Gaurav,**External Knowledge enabled Text Visual Question Answering**,arXiv:2108.09717 [cs] 2021 [[Paper]](http://arxiv.org/abs/2108.09717)

- Gamage, Bhanuka Manesha Samarasekara Vitharana and Hong, Lim Chern,**Improved RAMEN: Towards Domain Generalization for Visual Question Answering**,arXiv:2109.02370 [cs] 2021 [[Paper]](http://arxiv.org/abs/2109.02370)

- Gat, Itai and Schwartz, Idan and Schwing, Alexander,**Perceptual Score: What Data Modalities Does Your Model Perceive?**,Advances in Neural Information Processing Systems 2021 [[Paper]](http://arxiv.org/abs/2110.14375)

- Garcia-Olano, Diego and Onoe, Yasumasa and Ghosh, Joydeep,**Improving and Diagnosing Knowledge-Based Visual Question Answering via 
Entity Enhanced Knowledge Injection**,arXiv:2112.06888 [cs] 2021 [[Paper]](http://arxiv.org/abs/2112.06888)

- Gui, Liangke and Wang, Borui and Huang, Qiuyuan and Hauptmann, Alex and Bisk, Yonatan and Gao, Jianfeng,**KAT: A Knowledge Augmented Transformer for Vision-and-Language**,arXiv:2112.08614 [cs] 2021 [[Paper]](http://arxiv.org/abs/2112.08614)

- Eslami, Sedigheh and de Melo, Gerard and Meinel, Christoph,**Does CLIP Benefit Visual Question Answering in the Medical Domain as Much as it Does in the General Domain?**,arXiv:2112.13906 [cs] 2021 [[Paper]](http://arxiv.org/abs/2112.13906)


## 2022-1-21
- Azuma, Daichi and Miyanishi, Taiki and Kurita, Shuhei and Kawanabe, Motoki,**ScanQA: 3D Question Answering for Spatial Scene Understanding**,arXiv:2112.10482 [cs] 2021 [[Paper]](http://arxiv.org/abs/2112.10482)
 
- Biten, Ali Furkan and Litman, Ron and Xie, Yusheng and Appalaraju, Srikar and Manmatha, R.,**LaTr: Layout-Aware Transformer 
for Scene-Text VQA**,arXiv:2112.12494 [cs] 2021 [[Paper]](http://arxiv.org/abs/2112.12494)

- Banerjee, Pratyay and Gokhale, Tejas and Yang, Yezhou and Baral, Chitta,**WeaQA: Weak Supervision via Captions for Visual Question Answering**,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021 2021 [[Paper]](http://arxiv.org/abs/2012.02356)

- Song, Dandan and Ma, Siyi and Sun, Zhanchen and Yang, Sicheng and Liao, Lejian,**KVL-BERT: Knowledge Enhanced Visual-and-Linguistic BERT for Visual Commonsense Reasoning**,arXiv:2012.07000 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.07000)

- Cao, Qingxing and Li, Bailin and Liang, Xiaodan and Wang, Keze and Lin, Liang,**Knowledge-Routed Visual Question Reasoning: 
Challenges for Deep Representation Embedding**,IEEE Transactions on Neural Networks and Learning Systems 2020 [[Paper]](http://arxiv.org/abs/2012.07192)

- Yang, Chao and Feng, Su and Li, Dongsheng and Shen, Huawei and Wang, Guoqing and Jiang, Bin,**Learning content and context with language bias for Visual Question Answering**,2021 IEEE International Conference on Multimedia and Expo (ICME) 2020 [[Paper]](http://arxiv.org/abs/2012.11134)

- Zhu, Xi and Mao, Zhendong and Liu, Chunxiao and Zhang, Peng and Wang, Bin and Zhang, Yongdong,**Overcoming Language Priors with Self-supervised Learning for Visual Question Answering**,arXiv:2012.11528 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.11528)

- Whitehead, Spencer and Wu, Hui and Fung, Yi Ren and Ji, Heng and Feris, Rogerio and Saenko, Kate,**Learning from Lexical Perturbations for Consistent Visual Question Answering**,arXiv:2011.13406 [cs] 2020 [[Paper]](http://arxiv.org/abs/2011.13406)   

- Damodaran, Vinay and Chakravarthy, Sharanya and Kumar, Akshay and Umapathy, Anjana and Mitamura, Teruko and Nakashima, Yuta 
and Garcia, Noa and Chu, Chenhui,**Understanding the Role of Scene Graphs in Visual Question Answering**,arXiv:2101.05479 [cs] 2021 [[Paper]](http://arxiv.org/abs/2101.05479)

- Barra, Silvio and Bisogni, Carmen and De Marsico, Maria and Ricciardi, Stefano,**Visual Question Answering: which investigated applications?**,arXiv:2103.02937 [cs] 2021 [[Paper]](http://arxiv.org/abs/2103.02937)

- Berlot-Attwell, Ian,**Neuro-Symbolic VQA: A review from the perspective of AGI desiderata**,arXiv:2103.02937 [cs] 2021 [[Paper]](https://arxiv.org/abs/2104.06365v1)

- Dancette, Corentin and Cadene, Remi and Teney, Damien and Cord, Matthieu,**Beyond Question-Based Biases: Assessing Multimodal Shortcut Learning in Visual Question Answering**,arXiv:2104.03149 [cs] 2021 [[Paper]](http://arxiv.org/abs/2104.03149)      

- Cho, Jae Won and Kim, Dong-Jin and Choi, Jinsoo and Jung, Yunjae and Kweon, In So,**Dealing with Missing Modalities in the Visual Question Answer-Difference Prediction Task through Knowledge Distillation**,Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2021 [[Paper]](http://arxiv.org/abs/2104.05965)

- Zou, Yeyun and Xie, Qiyu,**A survey on VQA_Datasets and Approaches**,2020 2nd International Conference on Information Technology and Computer Application (ITCA) 2020 [[Paper]](http://arxiv.org/abs/2105.00421)

- Comment: arXiv admin note: text overlap with arXiv:1706.07230 by other authors,**Grounding Complex Navigational Instructions Using Scene Graphs**,arXiv:2106.01607 [cs] 2021 [[Paper]](http://arxiv.org/abs/2106.01607)

- D'Amario, Vanessa and Sasaki, Tomotake and Boix, Xavier,**How Modular Should Neural Module Networks Be for Systematic Generalization?**,arXiv:2106.08170 [cs] 2021 [[Paper]](http://arxiv.org/abs/2106.08170)

- Chen, Zhuo and Chen, Jiaoyan and Geng, Yuxia and Pan, Jeff Z. and Yuan, Zonggang and Chen, Huajun,**Zero-shot Visual Question Answering using Knowledge Graph**,International Semantic Web Conference 2021 [[Paper]](http://arxiv.org/abs/2107.05348)     

- Banerjee, Pratyay and Gokhale, Tejas and Yang, Yezhou and Baral, Chitta,**Weakly Supervised Relative Spatial Reasoning for Visual Question Answering**,Proceedings of the IEEE/CVF International Conference on Computer Vision 2021 [[Paper]](http://arxiv.org/abs/2109.01934)

- Chappuis, Christel and Lobry, Sylvain and Kellenberger, Benjamin and Saux, Bertrand Le and Tuia, Devis,**How to find a good 
image-text embedding for remote sensing visual question answering?**,arXiv:2109.11848 [cs] 2021 [[Paper]](http://arxiv.org/abs/2109.11848)

- Chen, Long and Zheng, Yuhang and Niu, Yulei and Zhang, Hanwang and Xiao, Jun,**Counterfactual Samples Synthesizing and Training for Robust Visual Question Answering**,arXiv:2110.01013 [cs] 2021 [[Paper]](http://arxiv.org/abs/2110.01013)

- Cao, JianJian and Qin, Xiameng and Zhao, Sanyuan and Shen, Jianbing,**Bilateral Cross-Modality Graph Matching Attention for 
Feature Fusion in Visual Question Answering**,arXiv:2112.07270 [cs] 2021 [[Paper]](http://arxiv.org/abs/2112.07270)


## 2021-2-24
- Sharifzadeh, Sahand and Baharlou, Sina Moayed and Schmitt, Martin and Schütze, Hinrich and Tresp, Volker,**Improving {Visual} {Reasoning} by {Exploiting} {The} {Knowledge} in {Texts}**,arXiv:2102.04760 [cs] 2021 [[Paper]](http://arxiv.org/abs/2102.04760)
 
- Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc V. and Sung, Yunhsuan and Li, Zhen and Duerig, Tom,**Scaling {Up} {Visual} and {Vision}-{Language} {Representation} {Learning} {With} {Noisy} {Text} {Supervision}**,arXiv:2102.05918 [cs] 2021 [[Paper]](http://arxiv.org/abs/2102.05918)
 
- Davis, Ernest,**Unanswerable {Questions} about {Images} and {Texts}**,Frontiers in Artificial Intelligence 2020 [[Paper]](http://arxiv.org/abs/2102.06793)
 
- Liu, Bo and Zhan, Li-Ming and Xu, Li and Ma, Lin and Yang, Yan and Wu, Xiao-Ming,**{SLAKE}: {A} {Semantically}-{Labeled} {Knowledge}-{Enhanced} {Dataset} for {Medical} {Visual} {Question} {Answering}**,ISBI 2021 2021 [[Paper]](http://arxiv.org/abs/2102.09542)
 
- Guo, Dalu and Tao, Dacheng,**Learning {Compositional} {Representation} for {Few}-shot {Visual} {Question} {Answering}**,arXiv:2102.10575 [cs] 2021 [[Paper]](http://arxiv.org/abs/2102.10575)
 
- Le, Thao Minh and Le, Vuong and Venkatesh, Svetha and Tran, Truyen,**Dynamic {Language} {Binding} in {Relational} {Visual} {Reasoning}**,arXiv:2004.14603 [cs] 2021 [[Paper]](http://arxiv.org/abs/2004.14603)
 
- Zhang, Weifeng and Yu, Jing and Zhao, Wenhong and Ran, Chuan,**{DMRFNet}: {Deep} {Multimodal} {Reasoning} and {Fusion} for {Visual} {Question} {Answering} and explanation generation**,Information Fusion 2021 [[Paper]](https://www.sciencedirect.com/science/article/pii/S1566253521000208)

## 2021-2-9
- Kim, Jung-Jun and Lee, Dong-Gyu and Wu, Jialin and Jung, Hong-Gyu and Lee, Seong-Whan,**Visual {Question} {Answering} based on {Local}-{Scene}-{Aware} {Referring} {Expression} {Generation}**,arXiv:2101.08978 [cs] 2021 [[Paper]](http://arxiv.org/abs/2101.08978)
 
- Liu, Yibing and Guo, Yangyang and Yin, Jianhua and Song, Xuemeng and Liu, Weifeng and Nie, Liqiang,**Answer {Questions} with {Right} {Image} {Regions}: {A} {Visual} {Attention} {Regularization} {Approach}**,arXiv:2102.01916 [cs] 2021 [[Paper]](http://arxiv.org/abs/2102.01916)

## 2021-1-20
- Damodaran, Vinay and Chakravarthy, Sharanya and Kumar, Akshay and Umapathy, Anjana and Mitamura, Teruko and Nakashima, Yuta and Garcia, Noa and Chu, Chenhui,**Understanding the {Role} of {Scene} {Graphs} in {Visual} {Question} {Answering}**,arXiv:2101.05479 [cs] 2021 [[Paper]](http://arxiv.org/abs/2101.05479)
 
- Patel, Devshree and Parikh, Ratnam and Shastri, Yesha,**Recent {Advances} in {Video} {Question} {Answering}: {A} {Review} of {Datasets} and {Methods}**,arXiv:2101.05954 [cs] 2021 [[Paper]](http://arxiv.org/abs/2101.05954)
 
- Shevchenko, Violetta and Teney, Damien and Dick, Anthony and Hengel, Anton van den,**Reasoning over {Vision} and {Language}: {Exploring} the {Benefits} of {Supplemental} {Knowledge}**,arXiv:2101.06013 [cs] 2021 [[Paper]](http://arxiv.org/abs/2101.06013)
 
- Wang, Zixu and Miao, Yishu and Specia, Lucia,**Latent {Variable} {Models} for {Visual} {Question} {Answering}**,arXiv:2101.06399 [cs] 2021 [[Paper]](http://arxiv.org/abs/2101.06399)

## 2021-1-10
- Li, Wei and Gao, Can and Niu, Guocheng and Xiao, Xinyan and Liu, Hao and Liu, Jiachen and Wu, Hua and Wang, Haifeng,**{UNIMO}: {Towards} {Unified}-{Modal} {Understanding} and {Generation} via {Cross}-{Modal} {Contrastive} {Learning}**,arXiv:2012.15409 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.15409)
 
- Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng,**{VinVL}: {Making} {Visual} {Representations} {Matter} in {Vision}-{Language} {Models}**,arXiv:2101.00529 [cs] 2021 [[Paper]](http://arxiv.org/abs/2101.00529)
## 2020-12-26
- Uppal, Shagun and Bhagat, Sarthak and Hazarika, Devamanyu and Majumdar, Navonil and Poria, Soujanya and Zimmermann, Roger and Zadeh, Amir,**Multimodal {Research} in {Vision} and {Language}: {A} {Review} of {Current} and {Emerging} {Trends}**,arxiv 2020 [[Paper]](https://arxiv.org/abs/2010.09522v2)
 
- Gardères, François and Ziaeefard, Maryam and Abeloos, Baptiste and Lecue, Freddy,**{ConceptBert}: {Concept}-{Aware} {Representation} for {Visual} {Question} {Answering}**,Findings of the Association for Computational Linguistics:EMNLP 2020 2020 [[Paper]](https://www.aclweb.org/anthology/2020.findings-emnlp.44)
 
- Chen, Long and Yan, Xin and Xiao, Jun and Zhang, Hanwang and Pu, Shiliang and Zhuang, Yueting,**Counterfactual {Samples} {Synthesizing} for {Robust} {Visual} {Question} {Answering}**,IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2020 [[Paper]](https://ieeexplore.ieee.org/document/9157377/)
 
- Winterbottom, Thomas and Xiao, Sarah and McLean, Alistair and Moubayed, Noura Al,**On {Modality} {Bias} in the {TVQA} {Dataset}**,BMVC 2020 [[Paper]](http://arxiv.org/abs/2012.10210)
 
- Marino, Kenneth and Chen, Xinlei and Parikh, Devi and Gupta, Abhinav and Rohrbach, Marcus,**{KRISP}: {Integrating} {Implicit} and {Symbolic} {Knowledge} for {Open}-{Domain} {Knowledge}-{Based} {VQA}**,arXiv:2012.11014 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.11014)
 
- Yang, Jianwei and Mao, Jiayuan and Wu, Jiajun and Parikh, Devi and Cox, David D. and Tenenbaum, Joshua B. and Gan, Chuang,**Object-{Centric} {Diagnosis} of {Visual} {Reasoning}**,arXiv:2012.11587 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.11587)
 
- Zhu, Xi and Mao, Zhendong and Liu, Chunxiao and Zhang, Peng and Wang, Bin and Zhang, Yongdong,**Overcoming {Language} {Priors} with {Self}-supervised {Learning} for {Visual} {Question} {Answering}**,IJCAI 2020 [[Paper]](http://arxiv.org/abs/2012.11528)
 
- Dognin, Pierre and Melnyk, Igor and Mroueh, Youssef and Padhi, Inkit and Rigotti, Mattia and Ross, Jarret and Schiff, Yair and Young, Richard A. and Belgodere, Brian,**Image {Captioning} as an {Assistive} {Technology}: {Lessons} {Learned} from {VizWiz} 2020 {Challenge}**,arXiv:2012.11696 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.11696)
 
- Parcalabescu, Letitia and Gatt, Albert and Frank, Anette and Calixto, Iacer,**Seeing past words: {Testing} the cross-modal capabilities of pretrained {V}\&{L} models**,arXiv:2012.12352 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.12352)


## 2020-12-18
- Song, Dandan and Ma, Siyi and Sun, Zhanchen and Yang, Sicheng and Liao, Lejian,**{KVL}-{BERT}: {Knowledge} {Enhanced} {Visual}-and-{Linguistic} {BERT} for {Visual} {Commonsense} {Reasoning}**,arXiv:2012.07000 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.07000)
 
- Cao, Qingxing and Li, Bailin and Liang, Xiaodan and Wang, Keze and Lin, Liang,**Knowledge-{Routed} {Visual} {Question} {Reasoning}: {Challenges} for {Deep} {Representation} {Embedding}**,arXiv:2012.07192 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.07192)
 
- Wang, Jianfeng and Hu, Xiaowei and Zhang, Pengchuan and Li, Xiujun and Wang, Lijuan and Zhang, Lei and Gao, Jianfeng and Liu, Zicheng,**{MiniVLM}: {A} {Smaller} and {Faster} {Vision}-{Language} {Model}**,arXiv:2012.06946 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.06946)
 
- Li, Linjie and Gan, Zhe and Liu, Jingjing,**A {Closer} {Look} at the {Robustness} of {Vision}-and-{Language} {Pre}-trained {Models}**,arXiv:2012.08673 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.08673)

## 2020-12-11
- Banerjee, Pratyay and Gokhale, Tejas and Yang, Yezhou and Baral, Chitta,**Self-{Supervised} {VQA}: {Answering} {Visual} {Questions} using {Images} and {Captions}**,arXiv:2012.02356 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.02356)
 
- Patel, Alkesh and Bindal, Akanksha and Kotek, Hadas and Klein, Christopher and Williams, Jason,**Generating {Natural} {Questions} from {Images} for {Multimodal} {Assistants}**,arXiv:2012.03678 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.03678)
 
- Yang, Zhengyuan and Lu, Yijuan and Wang, Jianfeng and Yin, Xi and Florencio, Dinei and Wang, Lijuan and Zhang, Cha and Zhang, Lei and Luo, Jiebo,**{TAP}: {Text}-{Aware} {Pre}-training for {Text}-{VQA} and {Text}-{Caption}**,arXiv:2012.04638 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.04638)
 
- Zhu, Qi and Gao, Chenyu and Wang, Peng and Wu, Qi,**Simple is not {Easy}: {A} {Simple} {Strong} {Baseline} for {TextVQA} and {TextCaps}**,arXiv:2012.05153 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.05153)

## 2020-12-4
- Ma, Jie and Liu, Jun and Li, Junjun and Zheng, Qinghua and Yin, Qingyu and Zhou, Jianlong and Huang, Yi,**{XTQA}: {Span}-{Level} {Explanations} of the {Textbook} {Question} {Answering}**,arXiv:2011.12662 [cs] 2020 [[Paper]](http://arxiv.org/abs/2011.12662)
 
- Mani, Arjun and Hinthorn, Will and Yoo, Nobline and Russakovsky, Olga,**Point and {Ask}: {Incorporating} {Pointing} into {Visual} {Question} {Answering}**,arXiv:2011.13681 [cs] 2020 [[Paper]](http://arxiv.org/abs/2011.13681)
 
- Whitehead, Spencer and Wu, Hui and Fung, Yi Ren and Ji, Heng and Feris, Rogerio and Saenko, Kate,**Learning from {Lexical} {Perturbations} for {Consistent} {Visual} {Question} {Answering}**,arXiv:2011.13406 [cs] 2020 [[Paper]](http://arxiv.org/abs/2011.13406)
 
- Hong, Xin and Lan, Yanyan and Pang, Liang and Guo, Jiafeng and Cheng, Xueqi,**Transformation {Driven} {Visual} {Reasoning}**,arXiv:2011.13160 [cs] 2020 [[Paper]](http://arxiv.org/abs/2011.13160)
 
- Bugliarello, Emanuele and Cotterell, Ryan and Okazaki, Naoaki and Elliott, Desmond,**Multimodal {Pretraining} {Unmasked}: {Unifying} the {Vision} and {Language} {BERTs}**,arXiv:2011.15124 [cs] 2020 [[Paper]](http://arxiv.org/abs/2011.15124)

